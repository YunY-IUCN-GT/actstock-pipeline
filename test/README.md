## âš™ï¸ ì‚¬ì „ ì„¤ì • ë° ì„¤ì¹˜ (Setup)

ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— í•„ìš”í•œ Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. ì „ìš© í™˜ê²½ í™œì„±í™”
```cmd
conda activate conda_DE
```

### 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
`test` ë””ë ‰í† ë¦¬ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.
```cmd
pip install psycopg2-binary yfinance pandas python-dotenv
```
ë˜ëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ `pip install -r requirements.txt`ë¥¼ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.

---

## ğŸ“ í´ë” êµ¬ì¡°

```
test/
â”œâ”€â”€ README.md                          # ì´ íŒŒì¼
â”œâ”€â”€ 1_backfill_etf_benchmarks.py      # [ë°±í•„ 1ë‹¨ê³„] ETF ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë°±í•„
â”œâ”€â”€ 1_run_backfill.bat                # [ì‹¤í–‰] ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (Windows)
â”œâ”€â”€ test.sh                           # [ì‹¤í–‰] ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Linux/Mac)
â”œâ”€â”€ spark_jobs_launcher.sh            # [ì‹¤í–‰] Spark Job ìˆ˜ë™ ì‹¤í–‰
â””â”€â”€ unit_tests/                       # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
    â””â”€â”€ test_spark_jobs.py            # Spark Job í…ŒìŠ¤íŠ¸
```

---

## ğŸ”„ ë°±í•„ ì›Œí¬í”Œë¡œìš° (Backfill Workflow)

ì‹œìŠ¤í…œì„ ì²˜ìŒ ì‹œì‘í•˜ê±°ë‚˜ ê³¼ê±° ë°ì´í„°ë¥¼ ì±„ìš¸ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ì‹¤í–‰ ìˆœì„œ

#### âœ… 1ë‹¨ê³„: ETF ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë°±í•„ (í•„ìˆ˜)

**íŒŒì¼**: `1_backfill_etf_benchmarks.py`

**ëª©ì **: SPY ë° 15ê°œ ìœ ë‹ˆí¬ ETFì˜ ê³¼ê±° ì¼ë³„ OHLC ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ `collected_01_daily_etf_ohlc` í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… **ìŠ¤ë§ˆíŠ¸ ìºì‹±**: ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ë¥¼ 24ì‹œê°„ ë™ì•ˆ ë¡œì»¬ ìºì‹œ ì €ì¥
- âœ… **ê±°ë˜ì¼ ê¸°ì¤€**: `--days` íŒŒë¼ë¯¸í„°ëŠ” ê±°ë˜ì¼ ìˆ˜ë¥¼ ì˜ë¯¸ (ì˜ì—…ì¼ ê¸°ì¤€)
- âœ… **Rate-limit ë³´í˜¸**: yfinance ì œí•œ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨ ë° ì¬ê°œ ì‹œê°„ í‘œì‹œ
- âœ… **ì¬ì‹¤í–‰ ì•ˆì „**: ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ 24ì‹œê°„ ë‚´ ì¬ì‹¤í–‰ ì‹œ API í˜¸ì¶œ ì—†ìŒ

**ëŒ€ìƒ ETF (15ê°œ)**:
- **ë²¤ì¹˜ë§ˆí¬ (6ê°œ)**: SPY, QQQ, IWM, EWY, DIA, SCHD
- **ì„¹í„° (10ê°œ)**: QQQ, XLV, XLF, XLY, XLC, XLI, XLP, XLU, XLRE, XLB
- *(ì°¸ê³ : QQQëŠ” ì–‘ì  ì—­í• ì„ ëª¨ë‘ ìˆ˜í–‰í•˜ë©° ì´ ìœ ë‹ˆí¬ ê°œìˆ˜ëŠ” 15ê°œì…ë‹ˆë‹¤)*

**ì‹¤í–‰ ë°©ë²•**:

```bash
# Windows (ê¸°ë³¸ ì‹¤í–‰: 20 ê±°ë˜ì¼)
test\1_run_backfill.bat

# Linux/Mac (ê¸°ë³¸ ì‹¤í–‰: 20 ê±°ë˜ì¼, ìºì‹œ í™œì„±í™”)
docker-compose exec api python /app/test/1_backfill_etf_benchmarks.py
```

**íŒŒë¼ë¯¸í„°**:
- `--days`: ë°±í•„í•  ê³¼ê±° ê±°ë˜ì¼ ìˆ˜ (ê¸°ë³¸ê°’: 20 ê±°ë˜ì¼)
- `--delay`: API ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ ì´ˆ (ê¸°ë³¸ê°’: 5.0ì´ˆ)
- `--rate-limit-sleep`: Rate-limit ê°ì§€ ì‹œ ê¶Œì¥ ëŒ€ê¸° ì‹œê°„ (ê¸°ë³¸ê°’: 900ì´ˆ = 15ë¶„)
- `--no-batch`: ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ ë¹„í™œì„±í™” (í‹°ì»¤ë³„ ìˆœì°¨ ì²˜ë¦¬)
- `--max-retries`: ë‹¤ìš´ë¡œë“œ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3íšŒ)

**ìºì‹± ë™ì‘**:
- ìºì‹œ ì €ì¥ ìœ„ì¹˜: `test/.cache/`
- ìºì‹œ ìœ íš¨ ê¸°ê°„: 24ì‹œê°„
- ì¬ì‹¤í–‰ ì‹œ ìºì‹œ ìë™ ì‚¬ìš© (API í˜¸ì¶œ ì—†ìŒ)

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 
- ì²« ì‹¤í–‰ (API): ì•½ 20-30ì´ˆ (15ê°œ ETF Ã— 20 ê±°ë˜ì¼)
- ì¬ì‹¤í–‰ (ìºì‹œ): ì•½ 1ì´ˆ

**ì™„ë£Œ í™•ì¸**:
```sql
-- PostgreSQLì—ì„œ í™•ì¸
SELECT ticker, COUNT(*) as record_count, MIN(trade_date), MAX(trade_date)
FROM collected_01_daily_etf_ohlc
GROUP BY ticker
ORDER BY ticker;
```

---

#### âœ… 2ë‹¨ê³„: ì„¹í„° ETF ë°±í•„ - Staggered Runner (ì„ íƒ)

**íŒŒì¼**: `2_staggered_sector_backfill.py`, `2_run_staggered.bat`

**ëª©ì **: ì„¹í„° ETF ë°ì´í„°ë¥¼ **Rate-Limit ì—†ì´ ì•ˆì „í•˜ê²Œ** ë°±í•„í•©ë‹ˆë‹¤. í‹°ì»¤ë‹¹ ì¼ì • ê°„ê²©(ê¸°ë³¸ 5ë¶„)ìœ¼ë¡œ ìˆœì°¨ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¸°ëŠ¥**:
- âœ… **Rate-Limit ë°©ì§€**: 1ê°œ í‹°ì»¤ì”© 5ë¶„ ê°„ê²©ìœ¼ë¡œ ìˆ˜ì§‘ (429 ì—ëŸ¬ ì˜ˆë°©)
- âœ… **ìŠ¤ë§ˆíŠ¸ ìŠ¤í‚µ**: ì´ë¯¸ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” í‹°ì»¤ ìë™ ê±´ë„ˆë›°ê¸° (`--skip-existing`)
- âœ… **ì¬ê°œ ê°€ëŠ¥**: ì¤‘ë‹¨ ì‹œ íŠ¹ì • í‹°ì»¤ë¶€í„° ì¬ê°œ ê°€ëŠ¥ (`--start-from TICKER`)
- âœ… **ì§„í–‰ ì¶”ì **: í˜„ì¬ ì§„í–‰ë¥  ë° ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ í‘œì‹œ

**ëŒ€ìƒ ETF** (10ê°œ ì„¹í„°):
- QQQ, XLV, XLF, XLY, XLC, XLI, XLP, XLU, XLRE, XLB

**ì‹¤í–‰ ë°©ë²•**:

```bash
# Windows (ê°„í¸ ì‹¤í–‰: ê¸°ë³¸ 20ì¼, 5ë¶„ ê°„ê²©, ê¸°ì¡´ ë°ì´í„° ìŠ¤í‚µ)
test\2_run_staggered.bat

# Linux/Mac (ìˆ˜ë™ ì‹¤í–‰)
docker compose exec -T api sh -lc "cd /app && PYTHONPATH=/app python test/2_staggered_sector_backfill.py --days 20 --delay-minutes 5.0 --skip-existing"
```

**íŒŒë¼ë¯¸í„°**:
- `--days`: ë°±í•„í•  ê³¼ê±° ê±°ë˜ì¼ ìˆ˜ (ê¸°ë³¸ê°’: 20)
- `--delay-minutes`: í‹°ì»¤ ê°„ ëŒ€ê¸° ì‹œê°„ ë¶„ (ê¸°ë³¸ê°’: 5.0ë¶„)
- `--skip-existing`: ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” í‹°ì»¤ ê±´ë„ˆë›°ê¸°
- `--start-from TICKER`: íŠ¹ì • í‹°ì»¤ë¶€í„° ì¬ê°œ (ì˜ˆ: `--start-from XLV`)

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**:
- **10ê°œ ì„¹í„° ETF** Ã— 5ë¶„ = **ì•½ 50ë¶„**

**ì¤‘ë‹¨ ë° ì¬ê°œ**:
ì‹¤í–‰ ì¤‘ **Ctrl+C**ë¡œ ì¤‘ë‹¨ ê°€ëŠ¥. í™”ë©´ì— ì¬ê°œ ëª…ë ¹ì´ í‘œì‹œë©ë‹ˆë‹¤:
```
To resume, run with: --start-from XLV
```

---

#### âœ… 3ë‹¨ê³„: 5-Stage íŒŒì´í”„ë¼ì¸ í™•ì¸ (Airflow ìë™ ìŠ¤ì¼€ì¤„)

âš ï¸ **ì‹¤ì‹œê°„/ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì§‘ì€ í•˜ì§€ ì•ŠìŒ** - Airflow ìŠ¤ì¼€ì¤„ ë°°ì¹˜ë§Œ ì‚¬ìš©

**5-Stage Daily Pipeline** (ì›”-ê¸ˆ 21:30 UTC ë¶€í„° ìˆœì°¨ ì‹œì‘):
1. **Stage 1 (Benchmark)**: `collected_01_daily_etf_ohlc`
2. **Stage 2 (Sector)**: `collected_01_daily_etf_ohlc`
3. **Stage 3 (Trending Analysis)**: `analytics_03_trending_etfs`
4. **Stage 4 (Holdings/Stock)**: `collected_04_etf_holdings`, `collected_06_daily_stock_history`
5. **Stage 5 (Allocation)**: `analytics_05_portfolio_allocation`

---

#### âœ… 4ë‹¨ê³„: Spark ë¶„ì„ Job ì‹¤í–‰ (ìë™ ë˜ëŠ” ìˆ˜ë™)

**ìë™ ì‹¤í–‰**: Airflow 5-Stage Pipeline Stage 3, Stage 5ì—ì„œ ìë™ ì‹¤í–‰

**ìˆ˜ë™ ì‹¤í–‰**:
```bash
# Spark Job ìˆ˜ë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
./test/spark_jobs_launcher.sh

# ë˜ëŠ” ì§ì ‘ ì‹¤í–‰ (ì˜ˆ: í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë¶„)
docker-compose exec spark-master bash -c "\
  /opt/spark/bin/spark-submit \
  --master local[2] \
  --driver-memory 2g \
  --executor-memory 2g \
  --packages org.postgresql:postgresql:42.6.0 \
  batch/spark_02_active_stock_allocator.py"
```

**ì™„ë£Œ í™•ì¸**:
```sql
SELECT as_of_date, period_days, COUNT(*) as stock_count
FROM analytics_05_portfolio_allocation
GROUP BY as_of_date, period_days
ORDER BY as_of_date DESC, period_days;
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)

**íŒŒì¼**: `unit_tests/test_spark_jobs.py`
Spark Jobì˜ SQL ì¿¼ë¦¬, ë°ì´í„° ë³€í™˜ ë¡œì§ ê²€ì¦

**ì‹¤í–‰**:
```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (test.sh ë‚´ë¶€ì—ì„œ pytest í˜¸ì¶œ)
./test/test.sh

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
cd test/unit_tests
python -m pytest test_spark_jobs.py -v
```

---

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë°±í•„ ì‹¤íŒ¨ ì‹œ

**ë¬¸ì œ**: `yfinance API rate limit exceeded`
- **í•´ê²° 1**: Staggered runner ì‚¬ìš© (`test\2_run_staggered.bat`)
- **í•´ê²° 2**: ìºì‹œëœ ë°ì´í„°ëŠ” 24ì‹œê°„ ìœ íš¨í•˜ë¯€ë¡œ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ API í˜¸ì¶œ ì—†ì´ ì§„í–‰ë©ë‹ˆë‹¤.
- **í•´ê²° 3**: `--delay` ê°’ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.

**ë¬¸ì œ**: `Connection to PostgreSQL failed`
- **í•´ê²°**: Docker ì»¨í…Œì´ë„ˆê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤ (`docker-compose ps`).

---

## ğŸ“ ìºì‹± ì‹œìŠ¤í…œ

ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ëŠ” íš¨ìœ¨ì ì¸ ìˆ˜ì§‘ì„ ìœ„í•´ ìŠ¤ë§ˆíŠ¸ ìºì‹±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

1. **ì²« ì‹¤í–‰**: yfinance APIì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ í›„ `test/.cache/`ì— ì €ì¥
2. **ì¬ì‹¤í–‰**: ìºì‹œê°€ ìœ íš¨í•˜ë©´(24ì‹œê°„ ì´ë‚´) API í˜¸ì¶œ ì—†ì´ ìºì‹œ ì‚¬ìš©
3. **ë§Œë£Œ ì‹œ**: 24ì‹œê°„ì´ ê²½ê³¼í•˜ë©´ ìë™ìœ¼ë¡œ APIì—ì„œ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ

---

## ğŸ“Š ë°ì´í„° ê²€ì¦

ë°±í•„ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ë‹¤ìŒ ì¿¼ë¦¬ë¡œ ë°ì´í„° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”:

```sql
-- 1. ìˆ˜ì§‘ëœ ETF ë°ì´í„° í™•ì¸
SELECT ticker, COUNT(*) FROM collected_01_daily_etf_ohlc GROUP BY ticker;

-- 2. ìˆ˜ì§‘ëœ ì£¼ì‹ ë°ì´í„° í™•ì¸  
SELECT ticker, COUNT(*) FROM collected_06_daily_stock_history GROUP BY ticker;

-- 3. í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ í™•ì¸
SELECT as_of_date, period_days, COUNT(*) FROM analytics_05_portfolio_allocation GROUP BY as_of_date, period_days;
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [ARCHITECTURE.md](../ARCHITECTURE.md) - ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
- [README.md](../README.md) - í”„ë¡œì íŠ¸ ê°œìš”
- [database/NAMING_CONVENTION.md](../database/NAMING_CONVENTION.md) - í…Œì´ë¸” ëª…ëª… ê·œì¹™
